---
title: "Week 5"
execute: 
  echo: false
---

```{r}
#| label: setup
#| message: false

library(tidyverse)
library(tidymodels)
library(marginaleffects)
library(easystats)
library(gt)

x <- read_csv("data/resume.csv", show_col_types = FALSE)
```


### Background Information

Bertrand, Marianne and Sendhil Mullainathan. 2004. "Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination." American Economic Review, 94 (4): 991â€“1013. Data cleaned and discussed in "Quantitative Social Science: An Introduction" by Kosuke Imai.

"We study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U.S. labor market."


### Overview

This document includes background material for Week 5. Copy selected parts of the material out to a document which is shared with students, and then give them the answers later. The main audience for this document is Teaching Fellows so that they are better prepared to lead discussions.

Day 1: Covers Wisdom and Justice
Day 2: Courage
Day 3: Temperance


### Day 1: Wisdom and Jutice

Feel free, in your breakout room, to use a different approach than what you see me doing in the main room. The most common example starts with the "Imagine that you are ..." sentence. There is no right answer! Lots of different sorts of people face different sorts of decisions and so have different questions. But all those people might end up using the same dataset in different ways.

Examples: 

  1) Imagine that you are a contemporary historian studying US employment discrimination in the year 2000. You are . . . 

  Implies that questions are just about the past, so the Preceptor Table includes only rows for people in the year 2000. Whether or not the historian is interested in a causal or predictive model is unclear. Might be both.

  2) Imagine that you are a UK policy analyst trying to forecast callback rates for different sorts of job applicants. You are . . .

  "Forecast" implies a predictive model. There is no interest in what would have happened if an applicant had characteristics other than those she, in fact, does have. We just want to (accurately) predict what happens to applicants **today** in the **UK**. So, the rows in our Preceptor Table have no overlap with the rows in other Preceptor Table examples here.

  3) Imagine that you are Lauren Jones, Secretary of Labor and Workforce Development in Massachusetts. You are interested in the problems women have getting jobs in Massachusetts. You are . . .

  Again, the rows of the Preceptor Table are different. Jones cares about today in all of Massachusetts, not 25 years ago in just Boston (plus Chicago). More important, for this problem, she just cares about women. So, the Precepto Table is smaller. But that also causes us to, potentially, filter data. If all we are interested is women, then perhaps we should just keep the data rows which feature women. Does she want a causal or predictive model? It depends! What questions is she trying to answer.


These three people are interested in fairly different questions, which means that they have different Preceptor Tables, which means that they face different problems in exploring the assumptions which allow for the creation of a Population Table. There are no right answers!


### Discussion

Subject: Discrimination

Broad question: Race and employment in the United States

Specific question: Effect of racially-coded names on call-backs in the 2020's for adults in Boston and Chicago applying for jobs.

Preceptor Table: 
  
  * Units: individuals or resumes or a-resume-sent-to-a-specific-opening?  
  
  * (Potential) Outcomes: call-back if black name, call-back if white name   
  
  * Causal/predictive: a causal model  
  
  * Covariates: sex, experience, veteran, 
  
  * Treatment: black name on resume versus white name on resume 

## Example Preceptor Table
  
```{r}
y <- tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       attitude_after_control = c("Yes*", "No", "...", "No*", "Yes*", "...", "Yes"),
       attitude_after_treated = c("Yes", "Yes*", "...", "No", "Yes", "...", "No*"),
       treatment = c("Black", "White", "...", "Black", "Black", "...", "White"),
       sex = c("female", "male", "...", "male", "female", "...", "female"))

 y |> 
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             attitude_after_control = md("Callback if White Name"),
             attitude_after_treated = md("Callback if Black Name"),
             sex = md("Sex"),
             treatment = md("Treatment")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Potential Outcomes", columns = c(attitude_after_control, attitude_after_treated)) |>
  tab_spanner(label = "Covariates", columns = c(treatment, sex))
```

## Preceptor Table

Imagine that you are an economist trying to understand discrimination in Boston/Chicago today.

> What are the units, precisely?

All the people sending out resumes for entry-level positions in Boston and Chicago during 2020 -- 2030 who have names which are associated with a race. So, N is (?) in the thousands.

> What is the moment in time, precisely?

2020 to 2030

> What is one reason why validity might not hold?

There is less of a strong connection between names and race today then there was in 2001. The column "resume with black name" in the data does not mean the same thing as the column "resume with black name" means in the Preceptor Table. Just because two columns have the same name does not mean that they are *really* the same thing.

> Describe the Population Table in words

Every time a person with a racially-coded name sends out a resume in Boston/Chicago between 2020 and 2030. That is, there will be multiple rows for the same person for two reasons. First, they will often apply for more than one job. Second, because they might apply for jobs in both 2022 and in, separately (and with a new resume), 2026.

> What is one reason why stability might not hold?

Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn. If racism has decrease significantly since 2001, then the relationship between the resume-with-black-name column and the callback outcome will not be as strong now as it was then.

> What is one reason why representativeness might not hold?

Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows. The original data from 2001 was not even real. They did not use real people. They were not sampling from the set of all job seekers. There is no reason to believe that the sorts of made-up-resumes they used are representative of the sorts of people/resumes applying for jobs now.


> What is one reason why unconfoundedness might not hold?

Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. A model is confounded if this is not true. Given that they randomly assigned names to resumes, unconfoundedness should be true. But what if the assignment process was not really random? They provide no details on the process. Is it that hard to believe that poorly-paid research assistants might not have bothered to really randomize the assignment of names to resumes?

> What would the Preceptor Table look like if we were trying to predict whether or not someone would get a callback?


```{r}
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       attitude_after_control = c("Yes", "No", "...", "No", "Yes", "...", "Yes"),
       treatment = c("Black", "White", "...", "Black", "Black", "...", "White"),
       sex = c("female", "male", "...", "male", "female", "...", "female")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             attitude_after_control = md("Callback"),
             sex = md("Sex"),
             treatment = md("Treatment")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(attitude_after_control)) |>
  tab_spanner(label = "Covariates", columns = c(treatment, sex))
```
 

## Scene 1

Repo --- maybe called `resume`? --- followed by computer project and Quarto document.

Load up the libraries you think we are going to need. Read in the data (nicely). Take a look at the data. 

```{r}
#| message: false
library(tidyverse)

x <- read_csv("data/resume.csv", show_col_types = FALSE)
```


## Day 2: Courage



## Day 3: Temperance

