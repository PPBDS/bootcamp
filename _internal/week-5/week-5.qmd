---
title: "Week 5"
execute: 
  echo: false
---

```{r}
#| message: false

library(gt)

library(tidyverse)
library(tidymodels)
library(broom)
library(easystats)
library(marginaleffects)

x <- read_csv("https://raw.githubusercontent.com/PPBDS/bootcamp/refs/heads/master/_internal/data/resume.csv",
        show_col_types = FALSE) |> 
          mutate(call = as.factor(call))
```

## Next Year

You need to provide students with the two "Imagine" scenarios. Don't have them waste time trying to come up with them on their own. Then, assign specific breakout rooms to work on one or the other. In the main room, we call of students for both and then discuss both.


## Background Information

Bertrand, Marianne and Sendhil Mullainathan. 2004. "Are Emily and Greg More Employable Than Lakisha and Jamal? A Field Experiment on Labor Market Discrimination." American Economic Review, 94 (4): 991â€“1013. Data cleaned and discussed in "Quantitative Social Science: An Introduction" by Kosuke Imai.

"We study race in the labor market by sending fictitious resumes to help-wanted ads in Boston and Chicago newspapers. To manipulate perceived race, resumes are randomly assigned African-American- or White-sounding names. White names receive 50 percent more callbacks for interviews. Callbacks are also more responsive to resume quality for White names than for African-American ones. The racial gap is uniform across occupation, industry, and employer size. We also find little evidence that employers are inferring social class from the names. Differential treatment by race still appears to still be prominent in the U.S. labor market."


## Overview

This document includes background material for Week 5. Copy selected parts of the material out to a document which is shared with students, and then give them the answers later. The main audience for this document is Teaching Fellows so that they are better prepared to lead discussions.

Day 1: Covers Wisdom and Justice
Day 2: Courage
Day 3: Temperance

Key lesson from last year is that we can't have students try to create their own "Imagine" sentence. That is too hard! Instead, we need to give them two "Imagine" sentences, one causal and one predictive, each asking about a different moment in time and a different set of units. Within that framework, they can then build a Preceptor Table and then examine the assumptions behind the creation of a Population Table.

Note that we use the same data, and the same statistical models, to help both people!

## Day 1: Wisdom

### Examples for students

1) Imagine that you are a contemporary historian studying US employment in the year 2000 in Baltimore. You want to understand the process by which some people got jobs and some did not.

2) Imagine that you work for a civil rights organization in Chicago. You want to understand the process by which black US citizens are discriminated against in hiring.

Repo -> project -> R script to explore the data. 

### Examine the data

  Implies that questions are just about the past, so the Preceptor Table includes only rows for people in the year 2000. Whether or not the historian is interested in a causal or predictive model is unclear. Might be both.

  2) Imagine that you are a UK policy analyst trying to forecast callback rates for different sorts of job applicants. You are . . .

  "Forecast" implies a predictive model. There is no interest in what would have happened if an applicant had characteristics other than those she, in fact, does have. We just want to (accurately) predict what happens to applicants **today** in the **UK**. So, the rows in our Preceptor Table have no overlap with the rows in other Preceptor Table examples here.

  3) Imagine that you are Lauren Jones, Secretary of Labor and Workforce Development in Massachusetts. You are interested in the problems women have getting jobs in Massachusetts. You are . . .

  Again, the rows of the Preceptor Table are different. Jones cares about today in all of Massachusetts, not 25 years ago in just Boston (plus Chicago). More important, for this problem, she just cares about women. So, the Precepto Table is smaller. But that also causes us to, potentially, filter data. If all we are interested is women, then perhaps we should just keep the data rows which feature women. Does she want a causal or predictive model? It depends! What questions is she trying to answer.


These three people are interested in fairly different questions, which means that they have different Preceptor Tables, which means that they face different problems in exploring the assumptions which allow for the creation of a Population Table. There are no right answers!


### Discussion

Subject: Discrimination

Broad question: Race and employment in the United States

Specific question: Effect of racially-coded names on call-backs in the 2020's for adults in Boston and Chicago applying for jobs.

Preceptor Table: 
  
  * Units: individuals or resumes or a-resume-sent-to-a-specific-opening?  
  
  * (Potential) Outcomes: call-back if black name, call-back if white name   
  
  * Causal/predictive: a causal model  
  
  * Covariates: sex, experience, veteran, 
  
  * Treatment: black name on resume versus white name on resume 

## Example Preceptor Table
  
```{r}
y <- tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       attitude_after_control = c("Yes*", "No", "...", "No*", "Yes*", "...", "Yes"),
       attitude_after_treated = c("Yes", "Yes*", "...", "No", "Yes", "...", "No*"),
       treatment = c("Black", "White", "...", "Black", "Black", "...", "White"),
       sex = c("female", "male", "...", "male", "female", "...", "female"))

 y |> 
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             attitude_after_control = md("Callback if White Name"),
             attitude_after_treated = md("Callback if Black Name"),
             sex = md("Sex"),
             treatment = md("Treatment")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Potential Outcomes", columns = c(attitude_after_control, attitude_after_treated)) |>
  tab_spanner(label = "Covariates", columns = c(treatment, sex))
```

## Preceptor Table

Imagine that you are an economist trying to understand discrimination in Boston/Chicago today.

> What are the units, precisely?

All the people sending out resumes for entry-level positions in Boston and Chicago during 2020 -- 2030 who have names which are associated with a race. So, N is (?) in the thousands.

> What is the moment in time, precisely?

2020 to 2030

> What is one reason why validity might not hold?

There is less of a strong connection between names and race today then there was in 2001. The column "resume with black name" in the data does not mean the same thing as the column "resume with black name" means in the Preceptor Table. Just because two columns have the same name does not mean that they are *really* the same thing.

> Describe the Population Table in words

Every time a person with a racially-coded name sends out a resume in Boston/Chicago between 2020 and 2030. That is, there will be multiple rows for the same person for two reasons. First, they will often apply for more than one job. Second, because they might apply for jobs in both 2022 and in, separately (and with a new resume), 2026.

> What is one reason why stability might not hold?

Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn. If racism has decrease significantly since 2001, then the relationship between the resume-with-black-name column and the callback outcome will not be as strong now as it was then.

> What is one reason why representativeness might not hold?

Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows. The original data from 2001 was not even real. They did not use real people. They were not sampling from the set of all job seekers. There is no reason to believe that the sorts of made-up-resumes they used are representative of the sorts of people/resumes applying for jobs now.


> What is one reason why unconfoundedness might not hold?

Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. A model is confounded if this is not true. Given that they randomly assigned names to resumes, unconfoundedness should be true. But what if the assignment process was not really random? They provide no details on the process. Is it that hard to believe that poorly-paid research assistants might not have bothered to really randomize the assignment of names to resumes?

> What would the Preceptor Table look like if we were trying to predict whether or not someone would get a callback?


```{r}
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       attitude_after_control = c("Yes", "No", "...", "No", "Yes", "...", "Yes"),
       treatment = c("Black", "White", "...", "Black", "Black", "...", "White"),
       sex = c("female", "male", "...", "male", "female", "...", "female")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             attitude_after_control = md("Callback"),
             sex = md("Sex"),
             treatment = md("Treatment")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(attitude_after_control)) |>
  tab_spanner(label = "Covariates", columns = c(treatment, sex))
```
 

 ## Day 1: Justice

## Scene 1

Repo --- maybe called `resume`? --- followed by computer project and Quarto document.

Load up the libraries you think we are going to need. Read in the data (nicely). Take a look at the data. 

```{r}
#| message: false
library(tidyverse)

x <- read_csv("data/resume.csv", show_col_types = FALSE)
```


## Day 2: Courage

These are just some quick notes about Courage. Still not sure how to handle this in class. Sorry! Will try to prepare better for Thursday and for next two weeks!

Consider two scenarios:

1) Imagine that you are a contemporary historian studying US employment in the year 2000 in Baltimore. You want to understand the process by which some people got jobs and some did not.

2) Imagine that you work for a civil rights organization in Chicago. You want to understand the process by which black US citizens are discriminated against in hiring today.

### Scene 1

* Look at the output variable call. Given it, what sort of model do you want to fit? What code creates such a model?

Because `call` is binary, we want a logistic model, which we created with `logistic_reg()`. Note that the default value of `engine` is `"glm"`, which is the most common approach to logistic models. 

If you group is going fast, they might want to experiment with other engines. The answers generated by two different engines will either be the same or different. Either case is interesting! The first shows that your conclusions are robust to which model you are using. The second shows that your conclusions are sensitive to the model.

### Scene 2

* Estimate a model in which `call` is the dependent variable and the `city` is the dependent variable. How do you interpret the results? How can you see some confidence intervals for the unknown parameters?

First time you do, you will get an error. Fix it and try again.


```{r}
logistic_reg() |> 
  fit(as.factor(call) ~ city, data = x)
```

`table(x$call, x$city)` is an interesting command to run since it shows fairly clearly that getting a call back is easier in Boston than in Chicago.

Basic interpretation is that callbacks are less likely to Chicago than Boston. Are you sure? How can we get some uncertainty?

```{r}
logistic_reg() |> 
  fit(as.factor(call) ~ city, data = x) |> 
  tidy(conf.int = TRUE)
```

Confidence intervals do not include zero, so you can be "sure" that callbacks are less common in Chicago. 

### Scene 3

Show the output of this code to AI. Ask for help in interpreting it. What is the probability of getting a callback in Boston versus Chicago? How certain/uncertain are you? I get:

````
The model shows Boston has a higher probability of call = 1 (9.7%, 95% CI: 8.0%â€“11.7%) than Chicago (6.7%, 95% CI: 5.2%â€“8.6%). The negative coefficient for citychicago (-0.397, 95% CI: -0.605 to -0.190, p = 1.70e-4) confirms a statistically significant decrease in log-odds for Chicago compared to Boston. The confidence intervals for the probabilities have minimal overlap, supporting that Bostonâ€™s probability is likely higher, though the difference is modest.
````

Advanced: How can the estimate for the coefficient of the Chicago dummy be statistically signficant if the confidence interval for the probabilities overlap? Subtle question! Ask AI.

### Scene 4

Add `ethnicity` to the model. Interpret the output. (Use AI.)

```{r}
logistic_reg() |> 
  fit(as.factor(call) ~ city + ethnicity, data = x) |> 
  tidy(conf.int = TRUE)
```

I get, along with lots of other stuff:

````
Summary of Probabilities
  Black in Boston: 7.8% (95% CI: 6.5%â€“9.2%)
  White in Boston: 11.6% (95% CI: 8.1%â€“16.3%)
  Black in Chicago: 5.4% (95% CI: 3.7%â€“7.7%)
  White in Chicago: 8.1% (95% CI: 4.6%â€“13.8%)
````

Note that we could use functions from **marginaleffects** to make similar calculations.  

```{r}
logistic_reg() |> 
  fit(as.factor(call) ~ city + ethnicity, data = x) |> 
  avg_predictions(type = "prob", by = c("city", "ethnicity")) 
```

Indeed, this is one of the big benefits of the **marginaleffects** package.

### Scene 5

Depending on time, we might encourage students to explore other models.

First, what other variables should we include? Try them! In general, we include anything sensible whose confidence intervals exclude zero.

Second, interaction effects? Note this line from the abstract: "Callbacks are also more responsive to resume quality for White names than for African-American ones." What sort of model allows us to conclude that? 

Third, consider making our model as similar to the one in the paper as possible.

There are no wrong answers!

Note that this simple model does not show quality doing anything.

```{r}
logistic_reg() |> 
  fit(as.factor(call) ~ city + ethnicity + quality + ethnicity*quality, data = x) |> 
  tidy(conf.int = TRUE)
```

If there is time, you can try `check_predictions(extract_fit_engine(fitted_obj))` after you create a fitted model.

### Scene 6

If there is time, we can discuss how the interpretation of the model differs between the two scenarios. 

In the predictive model case, we are just predicting whether or not resume X gets a callback, a probability which depends on her characteristics. And, in general, we don't just predict one resume. We predict the averages of different groups of people. The quantity of interest is across row, not within row.

In the causal model, we are predicting what would have happened to a resume if, counterfactually, it has a black name instead of a white name, or vice versa. And, we are almost always interested in the "causal effect," the difference between those two potential outcomes. The quantity of interest is within the row (for a single resume), not across rows.

In either case, we will be using **marginaleffects** to come up with these numbers and the associated graphics.


## Day 3: Temperance


```{r}
fit_call <- logistic_reg() |> 
    fit(call ~ gender + city + ethnicity + special + quality, data = x) 
```


## Scene 1

Fork repo. Render QMD. Cmd/Ctrl + Enter to get everything in the Console. 

Breakout rooms 1-6 use first Imagine. Rooms 7+ use second Imagine.

Describe the Population Table in words.

## Scene 2

Start writing summary paragraph. (AI may be helpful for individual sentences but won't give you a paragraph at once.)

Start playing with marginaleffects package. Run predictions(). What does the output mean? AI can help.


```{r}
predictions(fit_call, type = "prob")
```

```{r}
predictions(fit_call, type = "prob", by = "city")
```

```{r}
predictions(fit_call, type = "prob", by = "ethnicity")
```

## Scene 3

Start think about what sort of graphic you want to make. Start experimenting.


```{r}
plot_predictions(fit_call, type = "prob", by = "city")
```

```{r}
plot_predictions(fit_call, type = "prob", condition = "city")
```

```{r}
plot_predictions(fit_call, type = "prob", condition = c("ethnicity", "city"))
```

Explain the difference between `by` and `condition`.

```{r}
plot_predictions(fit_call, type = "prob", by = c("ethnicity", "city"))
```

The `condition` argument is used to plot conditional predictions, which are predictions made on a user-specified grid of predictor values.

Use `condition` when you want to explore how predictions vary across specific values of one or more predictors, holding others constant.


The `by` argument is used to plot marginal predictions, which are predictions computed on the original data but averaged by subgroups defined by one or more variables.

Use `by` when you want to visualize average predictions for specific subgroups in the data, rather than a hypothetical grid. This is useful for summarizing predictions across categorical or discrete variables.

I still find this confusing! I use `by` because I think I understand it . . .


## Scene 4

Come up with an "interesting" plot. You almost certainly want to use a vector of three variables for `by` or `condition`.

```{r}
plot_predictions(fit_call, 
                 type = "prob", 
                 by = c("quality", "ethnicity", "city"))
```


## Scene 5

But those plots are ugly, not least because seeing Yes and No for callback value is annoying. `draw = FALSE` and AI to make a nice looking plot.

## Scene 6

If you have time, make a website with this cool plot, and the finished summary paragraph.